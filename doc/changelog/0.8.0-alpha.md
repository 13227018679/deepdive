---
layout: default
title: Changes for 0.8.0
no_toc: true
---

# Changelog for Release 0.8.0-alpha (02/1X/2016)

A completely re-architected version of DeepDive is getting ready for release (v0.8) by the end of Jan 2016.
Now the system compiles an execution plan ahead of time, checkpoints at a much finer granularity, and gives users full visibility and control of the execution, so any parts of the computation can be flexibly repeated, resumed, or optimized later.
The new architecture naturally enforces modularity and extensibility, which enables future research projects to innovate most parts independently without having to understand everything.
The abstraction layers that encapsulate required database operations as well as compute resources are now clearly defined to allow the system to leverage even more types of database engines and compute clusters such as Hadoop/YARN and ones with traditional job schedulers.
As an artifact of this redesign, exciting performance improvements are now observed: the database drivers show more than 20x higher throughput (2MB/s -> 50MB/s, per connection) with zero storage footprint by streaming data in and out of UDFs, and the grounded factor graphs save up to 100x storage space (12GB -> 180MB) by employing compression while grounding and loading the factor graph incurring less than 10% time overhead (400s -> 460s, measuring only the dumping and loading).

* deepdive.extraction.extractors.\*.input should always be SQL queries. `TSV(filename.tsv)` or `CSV(filename.csv)` no longer supported.

* deepdive initdb -> deepdive db init
* deepdive initdb FOO -> deepdive compile; deepdive create table FOO

* deepdive run -> deepdive redo all
