#!/usr/bin/env bash
# configCompleted -- Extends normalized deepdive.conf further to include inference data flow
##
exec -a "$0" jq '.deepdive as $deepdive

# define the statistical modeling processes
| .deepdive.extraction.extractors += {
        # grounding the factor graph
        "process/model/grounding": {
            _dependencies: (.deepdive.inference.factors | keys),
            _output: "model/factorgraph",
            style: "cmd_extractor",
            # TODO run factor queries and grounding queries directly from here or via database drivers
            cmd: "
                set +x; . load-db-driver.sh; set -x
                mkdir -p ../../../model/factorgraph
                cd ../../../model
                java org.deepdive.Main -c <(
                    echo deepdive \(.deepdive_orig | @json | @sh)
                    echo deepdive.pipeline.pipelines.grounding: [\(.deepdive_orig.inference.factors | keys | join(" "))]
                    echo deepdive.pipeline.run: grounding
                ) -o factorgraph -t \"inference_grounding\"
                "
        },

        # learning weights
        "process/model/learning": {
            _dependencies: ["model/factorgraph"],
            _output: "model/weights",
            style: "cmd_extractor",
            # TODO run sampler directly
            cmd: "
                set +x; . load-db-driver.sh; set -x
                mkdir -p ../../../model/weights
                cd ../../../model
                java org.deepdive.Main -c <(
                    echo deepdive \(.deepdive_orig | @json | @sh)
                    echo deepdive.pipeline.pipelines.grounding: [\(.deepdive_orig.inference.factors | keys | join(" "))]
                    echo deepdive.pipeline.run: grounding
                ) -o model/factorgraph -t \"inference\"
                cp -f factorgraph/{graph.weights,inference_result.out.*} weights/
                "
        },

        # performing inference
        "process/model/inference": {
            _dependencies: ["model/factorgraph", "model/weights"],
            _output: "data/model/probabilities",
            style: "cmd_extractor",
            # TODO run sampler directly
            cmd: "
                set +x; . load-db-driver.sh; set -x
                mkdir -p ../../../model/weights
                cd ../../../model
                java org.deepdive.Main -c <(
                    echo deepdive \(.deepdive_orig | @json | @sh)
                    echo deepdive.pipeline.pipelines.grounding: [\(.deepdive_orig.inference.factors | keys | join(" "))]
                    echo deepdive.pipeline.run: grounding
                    echo deepdive.inference.skip_learning: true
                    echo deepdive.inference.relearn_from: true
                ) -o model/factorgraph -t \"inference\"
                cp -f factorgraph/{graph.weights,inference_result.out.*} weights/
                "
        },

        # calibration plots
        "process/model/calibration": {
            _dependencies: ["data/model/probabilities"],
            _output: "data/model/calibration-plots",
            style: "cmd_extractor",
            cmd: "error \"Not implemented yet (should run a script)\""
        },
    }

'
