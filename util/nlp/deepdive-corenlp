#!/usr/bin/env bash
# deepdive-corenlp -- DeepDive's interface to CoreNLP
#
# First, choose a unique port number for the CoreNLP HTTP server:
# $ export CORENLP_PORT=...
#
# Keep a CoreNLP HTTP server running in the background:
# $ deepdive corenlp server &
#
# Then stream documents for parsing into the CoreNLP server:
# $ deepdive corenlp parse \
# $     <TSJ_INPUT   COLUMN1_TO_DROP \
# $                  COLUMN2_TO_KEEP \
# $                  COLUMN3_TO_PARSE=NLP_OUTPUT1 \
# $                  COLUMN4_TO_KEEP \
# $                  COLUMN5_TO_PARSE=NLP_OUTPUT2 \
# $                  COLUMN6_TO_DROP \
# $     -- \
# $     >TSJ_OUTPUT  COLUMN4_TO_KEEP \
# $                  COLUMN2_TO_KEEP \
# $                  NLP_OUTPUT2 \
# $                  NLP_OUTPUT1 \
# $     #
# Remarks:
# - Input/output is in TSJ (tab-separated JSONs) format.
# - Document metadata can be easily associated with NLP results.
# - More than one blob of text can be parsed per document, e.g., abstract and full-text.
# - NLP result columns hold the raw JSON returned by CoreNLP intact.
# - Output columns can be reordered in any way.
#
# Finally, the raw CoreNLP results in a verbose JSON can be transformed into a
# simpler schema ("sentence" table) that is easier for use with DeepDive:
# $ deepdive corenlp sentences \
# $     <TSJ_OUTPUT     COLUMN4_TO_KEEP \
# $                     COLUMN2_TO_KEEP \
# $                     NLP_OUTPUT2=SENTENCES1 \
# $                     NLP_OUTPUT1=SENTENCES2 \
# $     -- \
# $     >TSJ_SENTENCES  COLUMN2_TO_KEEP \
# $                     SENTENCES1 \
# $     #
# Note that similar to the `parse` operator, columns can be kept or dropped
# and only one NLP result JSON can be unnested into a few columns for a row per
# sentence.
# 
##
set -euo pipefail

TODO
